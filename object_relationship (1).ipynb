{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAzsJCVUNd0r",
        "outputId": "5b793433-d46d-4127-f43e-31a47d6aa8dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dependencies"
      ],
      "metadata": {
        "id": "7OtltM0ciGnU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "X4KieV6wNqMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install --upgrade \"jax[cuda]\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html"
      ],
      "metadata": {
        "id": "B3W5vohMOx4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flax\n",
        "!pip install --upgrade git+https://github.com/google/flax.git"
      ],
      "metadata": {
        "id": "5AqliwrGPrjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-cache policy libcudnn8\n",
        "!apt install --allow-change-held-packages libcudnn8=8.4.1.50-1+cuda11.6\n",
        "!export PATH=/usr/local/cuda-11.4/bin${PATH:+:${PATH}}\n",
        "!export LD_LIBRARY_PATH=/usr/local/cuda-11.4/lib64:$LD_LIBRARY_PATH\n",
        "!export LD_LIBRARY_PATH=/usr/local/cuda-11.4/include:$LD_LIBRARY_PATH\n",
        "!export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/extras/CUPTI/lib64"
      ],
      "metadata": {
        "id": "0Dk21wBDUxxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import transformers\n",
        "from PIL import Image\n",
        "from transformers import ViTFeatureExtractor, AutoTokenizer, FlaxVisionEncoderDecoderModel\n",
        "import torch\n",
        "!pip install -U sentence-transformers\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "loc = \"ydshieh/vit-gpt2-coco-en\"\n",
        "feature_extractor = ViTFeatureExtractor.from_pretrained(loc)\n",
        "tokenizer = AutoTokenizer.from_pretrained(loc)\n",
        "image_cap_model = FlaxVisionEncoderDecoderModel.from_pretrained(loc)\n",
        "\n",
        "sentence_model = SentenceTransformer('sentence-transformers/LaBSE')"
      ],
      "metadata": {
        "id": "2e-Ak-F7Nh17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Process**"
      ],
      "metadata": {
        "id": "fyF6uFHxl8yd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_step(pixel_values, model):\n",
        "\n",
        "    output_ids = model.generate(pixel_values, max_length=16, num_beams=4).sequences\n",
        "    preds = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "\n",
        "    return preds\n",
        "\n",
        "def score_spatial_relation(text_prompt, image_path, sentence_model, image_cap_model):\n",
        "  # describe the image\n",
        "  with Image.open(image_path) as img:\n",
        "    all_pixels = feature_extractor(images=img, return_tensors=\"np\").pixel_values\n",
        "  detections = generate_step(all_pixels, image_cap_model)\n",
        "  print(\"Output Image Descripition: \",detections[0])\n",
        "\n",
        "  sentences = [detections[0],text_prompt]\n",
        "  # compute similarity by cos\n",
        "  embeddings = sentence_model.encode(sentences)\n",
        "  similarity = torch.cosine_similarity(torch.tensor(embeddings[0]), torch.tensor(embeddings[1]), dim=0)\n",
        "  print(\"Similarity: \",similarity.item())"
      ],
      "metadata": {
        "id": "a3I27xmpnk3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "text_prompt = 'an apple on the top of a box'\n",
        "image_path = '/content/drive/MyDrive/Datasets/dalle2_img/object_relation/DALLÂ·E 2022-11-06 09.57.34 - an apple on the top of a box.png'\n",
        "\n",
        "print(\"Input Text: \",text_prompt)\n",
        "# print(\"Input Image: \")\n",
        "# img = cv2.imread(image_path)\n",
        "# cv2_imshow(img)\n",
        "score_spatial_relation(text_prompt, image_path, sentence_model, image_cap_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iP5CpUUbEIPd",
        "outputId": "93d501b1-fa55-4beb-85ab-0af5a955b375"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Text:  an apple on the top of a box\n",
            "Output Image Descripition is:  a red apple sitting on top of a box\n",
            "Similarity is:  0.7727242112159729\n"
          ]
        }
      ]
    }
  ]
}